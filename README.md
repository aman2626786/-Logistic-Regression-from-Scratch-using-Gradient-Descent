# Logistic Regression from Scratch using Gradient Descent

Implemented **Logistic Regression from scratch** using **Gradient Descent** and compared it with `sklearn`'s `LogisticRegression`. ðŸš€

## ðŸ“Œ Key Features:
âœ” **Sigmoid Activation** for probability estimation  
âœ” **Gradient Descent Optimization** for parameter updates  
âœ” **Decision Boundary Visualization** comparing **manual vs sklearn implementation**  
âœ” **NumPy-based implementation** with step-by-step optimization  

## ðŸ“Š Results:
Both models successfully converge, and their decision boundaries closely match! ðŸŽ¯  

ðŸ“Œ Check out the full notebook for implementation details!  
